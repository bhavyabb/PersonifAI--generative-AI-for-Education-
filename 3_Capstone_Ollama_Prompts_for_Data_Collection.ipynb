{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "collapsed_sections": [
        "TKm0kQGMY8JP",
        "58aV23rfY_2_",
        "3ilCHphsZE2f",
        "H6WI8S17ZJH3",
        "g_-hUZCRZO6T",
        "7A8vffPoZVTb",
        "oC8oNSdHZd6w"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Installing Ollama:"
      ],
      "metadata": {
        "id": "TKm0kQGMY8JP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MD_KVAeq97KU",
        "outputId": "ec5fbc91-70a5-4d71-b94e-9de6ebaa5a7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpci3 pci.ids\n",
            "The following NEW packages will be installed:\n",
            "  libpci3 pci.ids pciutils\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 343 kB of archives.\n",
            "After this operation, 1,581 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 pci.ids all 0.0~2022.01.22-1 [251 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libpci3 amd64 1:3.7.0-6 [28.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 pciutils amd64 1:3.7.0-6 [63.6 kB]\n",
            "Fetched 343 kB in 1s (262 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package pci.ids.\n",
            "(Reading database ... 123598 files and directories currently installed.)\n",
            "Preparing to unpack .../pci.ids_0.0~2022.01.22-1_all.deb ...\n",
            "Unpacking pci.ids (0.0~2022.01.22-1) ...\n",
            "Selecting previously unselected package libpci3:amd64.\n",
            "Preparing to unpack .../libpci3_1%3a3.7.0-6_amd64.deb ...\n",
            "Unpacking libpci3:amd64 (1:3.7.0-6) ...\n",
            "Selecting previously unselected package pciutils.\n",
            "Preparing to unpack .../pciutils_1%3a3.7.0-6_amd64.deb ...\n",
            "Unpacking pciutils (1:3.7.0-6) ...\n",
            "Setting up pci.ids (0.0~2022.01.22-1) ...\n",
            "Setting up libpci3:amd64 (1:3.7.0-6) ...\n",
            "Setting up pciutils (1:3.7.0-6) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            ">>> Downloading ollama...\n",
            "############################################################################################# 100.0%\n",
            ">>> Installing ollama to /usr/local/bin...\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            ">>> NVIDIA GPU installed.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install -y pciutils\n",
        "!curl -fsSL https://ollama.com/install.sh | sh # download ollama api\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Create a Python script to start the Ollama API server in a separate thread\n",
        "\n",
        "import os\n",
        "import threading\n",
        "import subprocess\n",
        "import requests\n",
        "import json\n",
        "\n",
        "def ollama():\n",
        "    os.environ['OLLAMA_HOST'] = '0.0.0.0:11434'\n",
        "    os.environ['OLLAMA_ORIGINS'] = '*'\n",
        "    subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "ollama_thread = threading.Thread(target=ollama)\n",
        "ollama_thread.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pulling Llama 3.1 70B:"
      ],
      "metadata": {
        "id": "58aV23rfY_2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "!ollama pull llama3.1:70b\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "QGpTr3G1-Eyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U lightrag[ollama]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l54nWL-J-wlr",
        "outputId": "310d4cf3-f1cd-4d7f-c41b-9686b9d67c1c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightrag[ollama]\n",
            "  Downloading lightrag-0.1.0b6-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting backoff<3.0.0,>=2.2.1 (from lightrag[ollama])\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (3.1.4)\n",
            "Collecting jsonlines<5.0.0,>=4.0.0 (from lightrag[ollama])\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (1.6.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.4 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (1.26.4)\n",
            "Collecting python-dotenv<2.0.0,>=1.0.1 (from lightrag[ollama])\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (6.0.1)\n",
            "Collecting tiktoken<0.8.0,>=0.7.0 (from lightrag[ollama])\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.4 in /usr/local/lib/python3.10/dist-packages (from lightrag[ollama]) (4.66.5)\n",
            "Collecting ollama<0.3.0,>=0.2.1 (from lightrag[ollama])\n",
            "  Downloading ollama-0.2.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.3->lightrag[ollama]) (2.1.5)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines<5.0.0,>=4.0.0->lightrag[ollama]) (24.1.0)\n",
            "Collecting httpx<0.28.0,>=0.27.0 (from ollama<0.3.0,>=0.2.1->lightrag[ollama])\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.8.0,>=0.7.0->lightrag[ollama]) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.8.0,>=0.7.0->lightrag[ollama]) (2.32.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama])\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama])\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<0.8.0,>=0.7.0->lightrag[ollama]) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<0.8.0,>=0.7.0->lightrag[ollama]) (2.0.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama<0.3.0,>=0.2.1->lightrag[ollama]) (1.2.2)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading ollama-0.2.1-py3-none-any.whl (9.7 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightrag-0.1.0b6-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.1/159.1 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-dotenv, jsonlines, h11, backoff, tiktoken, httpcore, lightrag, httpx, ollama\n",
            "Successfully installed backoff-2.2.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jsonlines-4.0.0 lightrag-0.1.0b6 ollama-0.2.1 python-dotenv-1.0.1 tiktoken-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Extracting Data from Txt File:"
      ],
      "metadata": {
        "id": "3ilCHphsZE2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file_into_string(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            content = file.read()\n",
        "            return content\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File not found at {file_path}\")\n",
        "        return \"\"\n",
        "\n",
        "# Example usage\n",
        "file_path = \"/content/textdata5.txt\"\n",
        "content = read_file_into_string(file_path)"
      ],
      "metadata": {
        "id": "DEYCXfib_d5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prompt for creating Question Answer Dataset:"
      ],
      "metadata": {
        "id": "H6WI8S17ZJH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightrag.core.generator import Generator\n",
        "from lightrag.core.component import Component\n",
        "from lightrag.core.model_client import ModelClient\n",
        "from lightrag.components.model_client import OllamaClient, GroqAPIClient\n",
        "\n",
        "import time\n",
        "\n",
        "\n",
        "qa_template = r\"\"\"<SYS>\n",
        "You are an expert in generating question answer pairs from the text given below:\n",
        "</SYS>\n",
        "User: {{input_str}}\n",
        "Generate 200 theoretical questions and answers for every question and store them in a JSON. Do not repeat questions. Here is a simple format:\n",
        "{'question': ['what is data analysis?', '' ...],\n",
        " 'answer': ['Data analysis is ... ', '', ...]}\n",
        "You:\"\"\"\n",
        "\n",
        "class SimpleQA(Component):\n",
        "    def __init__(self, model_client: ModelClient, model_kwargs: dict):\n",
        "        super().__init__()\n",
        "        self.generator = Generator(\n",
        "            model_client=model_client,\n",
        "            model_kwargs=model_kwargs,\n",
        "            template=qa_template,\n",
        "        )\n",
        "\n",
        "    def call(self, input: dict) -> str:\n",
        "        return self.generator.call({\"input_str\": str(input)})\n",
        "\n",
        "    async def acall(self, input: dict) -> str:\n",
        "        return await self.generator.acall({\"input_str\": str(input)})"
      ],
      "metadata": {
        "id": "E3LBhe7--WpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lightrag.components.model_client import OllamaClient\n",
        "from IPython.display import Markdown, display\n",
        "model = {\n",
        "    \"model_client\": OllamaClient(),\n",
        "    \"model_kwargs\": {\"model\": \"llama3.1:70b\"}\n",
        "}\n",
        "# qa = SimpleQA(**model)\n",
        "# output=qa(content)\n",
        "# display(Markdown(f\"**Answer:** {output.data}\"))"
      ],
      "metadata": {
        "id": "KkKBitxU-8r9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##QA Dataset Raw Form:"
      ],
      "metadata": {
        "id": "g_-hUZCRZO6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa = SimpleQA(**model)\n",
        "output=qa(content)\n",
        "display(Markdown(f\"**Answer:** {output.data}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2jZOZftUXSSb",
        "outputId": "d7c81aed-d637-47c6-d836-ee550a122561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Answer:** Here are 200 theoretical questions and answers related to decision trees, machine learning, and data analysis in the JSON format you requested:\n\n```\n{\n    \"question\": [\n        \"What is a decision tree?\",\n        \"How does a decision tree work?\",\n        \"What is entropy in decision trees?\",\n        \"What is information gain in decision trees?\",\n        \"How do we choose the best split in a decision tree?\",\n        \"What is pruning in decision trees?\",\n        \"What is overfitting in machine learning?\",\n        \"How can we avoid overfitting in decision trees?\",\n        \"What is cross-validation in machine learning?\",\n        \"How does CART work?\",\n        \"What is Gini diversity index in CART?\",\n        \"How do we handle missing data in C4.5 algorithm?\",\n        \"What is the difference between C4.5 and CART algorithms?\",\n        \"Can a decision tree be used for regression tasks?\",\n        \"How can we evaluate the performance of a decision tree?\",\n        \"What is accuracy in machine learning?\",\n        \"What is precision in machine learning?\",\n        \"What is recall in machine learning?\",\n        \"What is F1-score in machine learning?\",\n        \"How do we handle continuous attributes in C4.5 algorithm?\",\n        \"Can a decision tree be used for multi-class classification tasks?\",\n        \"How can we improve the interpretability of a decision tree?\",\n        \"What is feature importance in decision trees?\",\n        \"How can we use decision trees for clustering tasks?\",\n        \"Can a decision tree be used for anomaly detection tasks?\",\n        \"How can we improve the robustness of a decision tree?\",\n        \"What is ensemble learning?\",\n        \"Can we combine multiple decision trees to improve performance?\",\n        \"What is bagging in ensemble learning?\",\n        \"What is boosting in ensemble learning?\",\n        \"How does random forest work?\",\n        \"What is gradient boosting?\",\n        \"How can we tune the hyperparameters of a decision tree?\",\n        \"What is grid search in hyperparameter tuning?\",\n        \"What is random search in hyperparameter tuning?\",\n        \"Can we use decision trees for text classification tasks?\",\n        \"Can we use decision trees for image classification tasks?\",\n        \"How can we improve the efficiency of a decision tree?\",\n        \"What is parallel processing in decision trees?\",\n        \"Can we distribute the computation of a decision tree across multiple machines?\",\n        \"What is distributed computing in decision trees?\",\n        \"How can we visualize the results of a decision tree?\",\n        \"What is visualization in machine learning?\",\n        \"Can we use decision trees for time series forecasting tasks?\",\n        \"Can we use decision trees for recommender systems?\",\n        \"How can we improve the scalability of a decision tree?\",\n        \"What is horizontal scaling in decision trees?\",\n        \"What is vertical scaling in decision trees?\",\n        \"Can we use decision trees for real-time prediction tasks?\",\n        \"How can we improve the reliability of a decision tree?\",\n        \"What is fault tolerance in decision trees?\",\n        \"Can we use decision trees for transfer learning tasks?\",\n        \"Can we use pre-trained decision trees as a feature extractor?\",\n        \"How can we fine-tune a pre-trained decision tree?\",\n        \"What is domain adaptation in decision trees?\",\n        \"Can we use decision trees for few-shot learning tasks?\",\n        \"Can we use decision trees for zero-shot learning tasks?\",\n        \"How can we improve the explainability of a decision tree?\",\n        \"What is feature attribution in decision trees?\",\n        \"Can we use decision trees for model interpretability tasks?\",\n        \"What is model interpretability in machine learning?\",\n        \"Can we use decision trees for uncertainty estimation tasks?\",\n        \"What is uncertainty estimation in machine learning?\",\n        \"How can we improve the robustness of a decision tree to adversarial attacks?\",\n        \"What is adversarial attack in machine learning?\",\n        \"Can we use decision trees for anomaly detection tasks?\",\n        \"Can we use decision trees for outlier detection tasks?\",\n        \"How can we improve the performance of a decision tree on imbalanced datasets?\",\n        \"What is class weighting in decision trees?\",\n        \"What is oversampling in decision trees?\",\n        \"What is undersampling in decision trees?\",\n        \"Can we use decision trees for feature selection tasks?\",\n        \"What is recursive feature elimination in decision trees?\",\n        \"Can we use decision trees for dimensionality reduction tasks?\",\n        \"What is principal component analysis in decision trees?\",\n        \"Can we use decision trees for clustering tasks?\",\n        \"What is k-means clustering in decision trees?\",\n        \"Can we use decision trees for density estimation tasks?\",\n        \"What is kernel density estimation in decision trees?\",\n        \"How can we improve the performance of a decision tree on high-dimensional data?\",\n        \"What is feature hashing in decision trees?\",\n        \"What is random projection in decision trees?\",\n        \"Can we use decision trees for parallel processing tasks?\",\n        \"What is MapReduce in decision trees?\",\n        \"Can we use decision trees for distributed computing tasks?\",\n        \"What is Spark in decision trees?\",\n        \"How can we improve the performance of a decision tree on large-scale data?\",\n        \"What is Hadoop in decision trees?\",\n        \"What is big data in machine learning?\",\n        \"Can we use decision trees for real-time processing tasks?\",\n        \"What is Apache Kafka in decision trees?\",\n        \"Can we use decision trees for streaming data tasks?\",\n        \"What is Apache Flink in decision trees?\",\n        \"How can we improve the performance of a decision tree on IoT devices?\",\n        \"What is edge computing in decision trees?\",\n        \"Can we use decision trees for real-time analytics tasks?\",\n        \"What is Apache Cassandra in decision trees?\",\n        \"Can we use decision trees for NoSQL databases?\",\n        \"What is graph database in decision trees?\",\n        \"How can we improve the performance of a decision tree on complex networks?\",\n        \"What is network analysis in decision trees?\",\n        \"Can we use decision trees for social network analysis tasks?\",\n        \"What is community detection in decision trees?\",\n        \"Can we use decision trees for recommendation systems?\",\n        \"What is collaborative filtering in decision trees?\",\n        \"How can we improve the performance of a decision tree on sequential data?\",\n        \"What is sequence prediction in decision trees?\",\n        \"Can we use decision trees for natural language processing tasks?\",\n        \"What is text classification in decision trees?\",\n        \"Can we use decision trees for image recognition tasks?\",\n        \"What is object detection in decision trees?\",\n        \"How can we improve the performance of a decision tree on audio data?\",\n        \"What is speech recognition in decision trees?\"\n    ],\n    \"answer\": [\n        \"A decision tree is a machine learning model that uses a tree-like structure to classify data or make predictions.\",\n        \"A decision tree works by recursively partitioning the data into smaller subsets based on the features of the data.\",\n        \"Entropy is a measure of the uncertainty or randomness in a dataset, and it is used in decision trees to determine the best split.\",\n        \"Information gain is the reduction in entropy that occurs when a decision tree splits the data into two subsets.\",\n        \"The best split in a decision tree is typically chosen based on the information gain, which is calculated using the Gini index or entropy.\",\n        \"Pruning is the process of removing branches from a decision tree to prevent overfitting and improve generalization.\",\n        \"Overfitting occurs when a machine learning model is too complex and fits the training data too closely, resulting in poor performance on new data.\",\n        \"To avoid overfitting in decision trees, we can use techniques such as pruning, regularization, or early stopping.\",\n        \"Cross-validation is a technique used to evaluate the performance of a machine learning model by splitting the data into training and testing sets.\",\n        \"CART (Classification and Regression Trees) is an algorithm for building decision trees that uses a binary split at each node.\",\n        \"The Gini diversity index is a measure of the impurity or heterogeneity of a dataset, and it is used in CART to determine the best split.\",\n        \"In C4.5 algorithm, missing data can be handled using techniques such as imputation, listwise deletion, or pairwise deletion.\",\n        \"C4.5 and CART are both algorithms for building decision trees, but they differ in their handling of continuous attributes and missing values.\",\n        \"Yes, a decision tree can be used for regression tasks by predicting the target variable instead of class labels.\",\n        \"The performance of a decision tree can be evaluated using metrics such as accuracy, precision, recall, F1-score, mean squared error, or R-squared.\",\n        \"Accuracy is the proportion of correct predictions made by a machine learning model.\",\n        \"Precision is the proportion of true positives among all predicted positive instances.\",\n        \"Recall is the proportion of true positives among all actual positive instances.\",\n        \"F1-score is the harmonic mean of precision and recall, providing a balanced measure of both metrics.\",\n        \"In C4.5 algorithm, continuous attributes can be handled using techniques such as binning or discretization.\",\n        \"Yes, a decision tree can be used for multi-class classification tasks by predicting multiple class labels instead of binary class labels.\",\n        \"The interpretability of a decision tree can be improved by visualizing the tree structure, using feature importance scores, or providing explanations for individual predictions.\",\n        \"Feature importance is a measure of the contribution of each feature to the predictions made by a machine learning model.\",\n        \"Yes, a decision tree can be used for clustering tasks by predicting cluster labels instead of class labels.\",\n        \"Anomaly detection involves identifying instances that are significantly different from the majority of the data, and decision trees can be used for this task.\",\n        \"The robustness of a decision tree can be improved using techniques such as pruning, regularization, or ensemble methods.\",\n        \"Ensemble learning is a technique that combines multiple machine learning models to improve performance and robustness.\",\n        \"Yes, we can combine multiple decision trees to improve performance by voting, bagging, or boosting.\",\n        \"The performance of a decision tree on large-scale data can be improved using distributed computing frameworks such as Hadoop or Spark.\"\n    ]\n}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(output.data)"
      ],
      "metadata": {
        "id": "1ftvcf-n_tOt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "220b5293-379d-46c0-d5a9-0aef3480363c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "ZmYUt63sSxYF",
        "outputId": "a9cc3afb-666e-41e9-f8a2-06933af51193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Here are some theoretical questions and answers related to the text you provided:\\n\\n```\\n{\\n  \"question\": [\\n    \"What is the difference between data science and data analytics?\",\\n    \"What are the types of analytics used in business decision-making?\",\\n    \"What is data literacy and why is it important?\",\\n    \"What is the data ecosystem and lifecycle?\",\\n    \"What is data privacy and what are its key components?\",\\n    \"What is disparate impact and why is it unlawful?\"\\n  ],\\n  \"answer\": [\\n    \"Data science focuses on asking questions and finding answers using data, while data analytics is used to extract insights from data to inform business decisions.\",\\n    \"There are four types of analytics: descriptive, diagnostic, predictive, and prescriptive. Each type provides different insights and is used for different purposes.\",\\n    \"Data literacy is the ability to read, understand, and utilize data in different ways. It is important because it enables non-data professionals to make informed decisions using data.\",\\n    \"The data ecosystem refers to the programming languages, packages, algorithms, cloud-computing services, and general infrastructure an organization uses to collect, store, analyze, and leverage data. The data lifecycle describes the path data takes from generation to interpretation.\",\\n    \"Data privacy is a subcategory of data protection that encompasses the ethical and legal obligation to protect access to personally identifiable information (PII). Its key components include what data is collected, how it is stored, and who can access it.\",\\n    \"Disparate impact refers to the unintentional harm caused by the use of data to an individual or group of people. It is unlawful because it discriminates against certain groups of people.\"\\n  ]\\n}\\n```\\n\\nLet me know if you\\'d like me to add more questions and answers!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loading QA Data into proper JSON Format:"
      ],
      "metadata": {
        "id": "7A8vffPoZVTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    result = json.loads(output.data)\n",
        "    # Display the converted JSON\n",
        "    print(\"Converted JSON:\", json.dumps(result, indent=2))\n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"Error decoding JSON: {e}\")\n",
        "    print(f\"Output data: {output.data}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1J9xx4OS0D_",
        "outputId": "d61ca190-4a97-4b4e-92bc-3a4eefe3f90f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n",
            "Output data: Here are some theoretical questions and answers related to the text you provided:\n",
            "\n",
            "```\n",
            "{\n",
            "  \"question\": [\n",
            "    \"What is the difference between data science and data analytics?\",\n",
            "    \"What are the types of analytics used in business decision-making?\",\n",
            "    \"What is data literacy and why is it important?\",\n",
            "    \"What is the data ecosystem and lifecycle?\",\n",
            "    \"What is data privacy and what are its key components?\",\n",
            "    \"What is disparate impact and why is it unlawful?\"\n",
            "  ],\n",
            "  \"answer\": [\n",
            "    \"Data science focuses on asking questions and finding answers using data, while data analytics is used to extract insights from data to inform business decisions.\",\n",
            "    \"There are four types of analytics: descriptive, diagnostic, predictive, and prescriptive. Each type provides different insights and is used for different purposes.\",\n",
            "    \"Data literacy is the ability to read, understand, and utilize data in different ways. It is important because it enables non-data professionals to make informed decisions using data.\",\n",
            "    \"The data ecosystem refers to the programming languages, packages, algorithms, cloud-computing services, and general infrastructure an organization uses to collect, store, analyze, and leverage data. The data lifecycle describes the path data takes from generation to interpretation.\",\n",
            "    \"Data privacy is a subcategory of data protection that encompasses the ethical and legal obligation to protect access to personally identifiable information (PII). Its key components include what data is collected, how it is stored, and who can access it.\",\n",
            "    \"Disparate impact refers to the unintentional harm caused by the use of data to an individual or group of people. It is unlawful because it discriminates against certain groups of people.\"\n",
            "  ]\n",
            "}\n",
            "```\n",
            "\n",
            "Let me know if you'd like me to add more questions and answers!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if output.data.strip():  # Ensures that output is not just whitespace\n",
        "    try:\n",
        "        result = json.loads(output.data)\n",
        "        # Display the converted JSON\n",
        "        print(\"Converted JSON:\", json.dumps(result, indent=2))\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error decoding JSON: {e}\")\n",
        "        print(f\"Output data: {output.data}\")\n",
        "else:\n",
        "    print(\"Received empty or whitespace-only output from the model.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If0yg30yTFPK",
        "outputId": "eccb8b53-c0a8-4bad-ed4e-2ea6943e8bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n",
            "Output data: Here are some generated theoretical questions and answers related to the text:\n",
            "\n",
            "[\n",
            "  {\n",
            "    \"question\": [\"What is secondary data analysis?\", \"Why is it important to follow established and systematic procedures when collecting secondary data?\"],\n",
            "    \"answer\": [\"Secondary data analysis is a research methodology that involves analyzing data collected by someone else, often for another purpose.\", \"It's crucial to follow established procedures to ensure accuracy and reliability of the results.\"]\n",
            "  },\n",
            "  {\n",
            "    \"question\": [\"What are some common steps in preparing secondary data for statistical analysis?\", \"How do you collect variables of interest in an established and systematic fashion?\"],\n",
            "    \"answer\": [\"The steps include planning, data collection, data storage, and data cleaning.\", \"You can collect variables of interest by downloading the necessary data files, collecting only the required variables, and using procedures like PROC MEANS to verify distributions.\"]\n",
            "  },\n",
            "  {\n",
            "    \"question\": [\"What are some benefits of creating a 'work' file in SAS?\", \"How do you save changes made to an analytic dataset in SAS?\"],\n",
            "    \"answer\": [\"Creating a 'work' file allows for temporary storage, and it's beneficial when making frequent changes.\", \"You can save changes using either the 'work' file or a 'permanent' file.\"]\n",
            "  },\n",
            "  {\n",
            "    \"question\": [\"What is the purpose of data storage in secondary data analysis?\", \"How do you ensure that original datasets are preserved?\"],\n",
            "    \"answer\": [\"Data storage ensures that original datasets are preserved, especially when using public sources.\", \"You can preserve original datasets by saving them separately and following rules set by the agency owning restricted data.\"]\n",
            "  }\n",
            "]\n",
            "\n",
            "Let me know if you'd like me to generate more questions and answers!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1l5c8wFHVAze",
        "outputId": "539cf54d-c015-4708-ad2a-6449e1b2493d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': ['What is the difference between data science and data analytics?',\n",
              "  'What are the types of analytics used in business decision-making?',\n",
              "  'What is data literacy and why is it important?',\n",
              "  'What is the data ecosystem and lifecycle?',\n",
              "  'What is data privacy and what are its key components?',\n",
              "  'What is disparate impact and why is it unlawful?'],\n",
              " 'answer': ['Data science focuses on asking questions and finding answers using data, while data analytics is used to extract insights from data to inform business decisions.',\n",
              "  'There are four types of analytics: descriptive, diagnostic, predictive, and prescriptive. Each type provides different insights and is used for different purposes.',\n",
              "  'Data literacy is the ability to read, understand, and utilize data in different ways. It is important because it enables non-data professionals to make informed decisions using data.',\n",
              "  'The data ecosystem refers to the programming languages, packages, algorithms, cloud-computing services, and general infrastructure an organization uses to collect, store, analyze, and leverage data. The data lifecycle describes the path data takes from generation to interpretation.',\n",
              "  'Data privacy is a subcategory of data protection that encompasses the ethical and legal obligation to protect access to personally identifiable information (PII). Its key components include what data is collected, how it is stored, and who can access it.',\n",
              "  'Disparate impact refers to the unintentional harm caused by the use of data to an individual or group of people. It is unlawful because it discriminates against certain groups of people.']}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_dict['answer']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wM_sY_MNVCI2",
        "outputId": "75206e9c-c296-49e2-8b30-319c7522c196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Data science focuses on asking questions and finding answers using data, while data analytics is used to extract insights from data to inform business decisions.',\n",
              " 'There are four types of analytics: descriptive, diagnostic, predictive, and prescriptive. Each type provides different insights and is used for different purposes.',\n",
              " 'Data literacy is the ability to read, understand, and utilize data in different ways. It is important because it enables non-data professionals to make informed decisions using data.',\n",
              " 'The data ecosystem refers to the programming languages, packages, algorithms, cloud-computing services, and general infrastructure an organization uses to collect, store, analyze, and leverage data. The data lifecycle describes the path data takes from generation to interpretation.',\n",
              " 'Data privacy is a subcategory of data protection that encompasses the ethical and legal obligation to protect access to personally identifiable information (PII). Its key components include what data is collected, how it is stored, and who can access it.',\n",
              " 'Disparate impact refers to the unintentional harm caused by the use of data to an individual or group of people. It is unlawful because it discriminates against certain groups of people.']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_dict = { \"question\": [ \"What is a decision tree?\", \"How does a decision tree work?\", \"What is entropy in decision trees?\", \"What is information gain in decision trees?\", \"How do we choose the best split in a decision tree?\", \"What is pruning in decision trees?\", \"What is overfitting in machine learning?\", \"How can we avoid overfitting in decision trees?\", \"What is cross-validation in machine learning?\", \"How does CART work?\", \"What is Gini diversity index in CART?\", \"How do we handle missing data in C4.5 algorithm?\", \"What is the difference between C4.5 and CART algorithms?\", \"Can a decision tree be used for regression tasks?\", \"How can we evaluate the performance of a decision tree?\", \"What is accuracy in machine learning?\", \"What is precision in machine learning?\", \"What is recall in machine learning?\", \"What is F1-score in machine learning?\", \"How do we handle continuous attributes in C4.5 algorithm?\", \"Can a decision tree be used for multi-class classification tasks?\", \"How can we improve the interpretability of a decision tree?\", \"What is feature importance in decision trees?\", \"How can we use decision trees for clustering tasks?\", \"Can a decision tree be used for anomaly detection tasks?\", \"How can we improve the robustness of a decision tree?\", \"What is ensemble learning?\", \"Can we combine multiple decision trees to improve performance?\", \"What is bagging in ensemble learning?\", \"What is boosting in ensemble learning?\", \"How does random forest work?\", \"What is gradient boosting?\", \"How can we tune the hyperparameters of a decision tree?\", \"What is grid search in hyperparameter tuning?\", \"What is random search in hyperparameter tuning?\", \"Can we use decision trees for text classification tasks?\", \"Can we use decision trees for image classification tasks?\", \"How can we improve the efficiency of a decision tree?\", \"What is parallel processing in decision trees?\", \"Can we distribute the computation of a decision tree across multiple machines?\", \"What is distributed computing in decision trees?\", \"How can we visualize the results of a decision tree?\", \"What is visualization in machine learning?\", \"Can we use decision trees for time series forecasting tasks?\", \"Can we use decision trees for recommender systems?\", \"How can we improve the scalability of a decision tree?\", \"What is horizontal scaling in decision trees?\", \"What is vertical scaling in decision trees?\", \"Can we use decision trees for real-time prediction tasks?\", \"How can we improve the reliability of a decision tree?\", \"What is fault tolerance in decision trees?\", \"Can we use decision trees for transfer learning tasks?\", \"Can we use pre-trained decision trees as a feature extractor?\", \"How can we fine-tune a pre-trained decision tree?\", \"What is domain adaptation in decision trees?\", \"Can we use decision trees for few-shot learning tasks?\", \"Can we use decision trees for zero-shot learning tasks?\", \"How can we improve the explainability of a decision tree?\", \"What is feature attribution in decision trees?\", \"Can we use decision trees for model interpretability tasks?\", \"What is model interpretability in machine learning?\", \"Can we use decision trees for uncertainty estimation tasks?\", \"What is uncertainty estimation in machine learning?\", \"How can we improve the robustness of a decision tree to adversarial attacks?\", \"What is adversarial attack in machine learning?\", \"Can we use decision trees for anomaly detection tasks?\", \"Can we use decision trees for outlier detection tasks?\", \"How can we improve the performance of a decision tree on imbalanced datasets?\", \"What is class weighting in decision trees?\", \"What is oversampling in decision trees?\", \"What is undersampling in decision trees?\", \"Can we use decision trees for feature selection tasks?\", \"What is recursive feature elimination in decision trees?\", \"Can we use decision trees for dimensionality reduction tasks?\", \"What is principal component analysis in decision trees?\", \"Can we use decision trees for clustering tasks?\", \"What is k-means clustering in decision trees?\", \"Can we use decision trees for density estimation tasks?\", \"What is kernel density estimation in decision trees?\", \"How can we improve the performance of a decision tree on high-dimensional data?\", \"What is feature hashing in decision trees?\", \"What is random projection in decision trees?\", \"Can we use decision trees for parallel processing tasks?\", \"What is MapReduce in decision trees?\", \"Can we use decision trees for distributed computing tasks?\", \"What is Spark in decision trees?\", \"How can we improve the performance of a decision tree on large-scale data?\", \"What is Hadoop in decision trees?\", \"What is big data in machine learning?\", \"Can we use decision trees for real-time processing tasks?\", \"What is Apache Kafka in decision trees?\", \"Can we use decision trees for streaming data tasks?\", \"What is Apache Flink in decision trees?\", \"How can we improve the performance of a decision tree on IoT devices?\", \"What is edge computing in decision trees?\", \"Can we use decision trees for real-time analytics tasks?\", \"What is Apache Cassandra in decision trees?\", \"Can we use decision trees for NoSQL databases?\", \"What is graph database in decision trees?\", \"How can we improve the performance of a decision tree on complex networks?\", \"What is network analysis in decision trees?\", \"Can we use decision trees for social network analysis tasks?\", \"What is community detection in decision trees?\", \"Can we use decision trees for recommendation systems?\", \"What is collaborative filtering in decision trees?\", \"How can we improve the performance of a decision tree on sequential data?\", \"What is sequence prediction in decision trees?\", \"Can we use decision trees for natural language processing tasks?\", \"What is text classification in decision trees?\", \"Can we use decision trees for image recognition tasks?\", \"What is object detection in decision trees?\", \"How can we improve the performance of a decision tree on audio data?\", \"What is speech recognition in decision trees?\" ], \"answer\": [ \"A decision tree is a machine learning model that uses a tree-like structure to classify data or make predictions.\", \"A decision tree works by recursively partitioning the data into smaller subsets based on the features of the data.\", \"Entropy is a measure of the uncertainty or randomness in a dataset, and it is used in decision trees to determine the best split.\", \"Information gain is the reduction in entropy that occurs when a decision tree splits the data into two subsets.\", \"The best split in a decision tree is typically chosen based on the information gain, which is calculated using the Gini index or entropy.\", \"Pruning is the process of removing branches from a decision tree to prevent overfitting and improve generalization.\", \"Overfitting occurs when a machine learning model is too complex and fits the training data too closely, resulting in poor performance on new data.\", \"To avoid overfitting in decision trees, we can use techniques such as pruning, regularization, or early stopping.\", \"Cross-validation is a technique used to evaluate the performance of a machine learning model by splitting the data into training and testing sets.\", \"CART (Classification and Regression Trees) is an algorithm for building decision trees that uses a binary split at each node.\", \"The Gini diversity index is a measure of the impurity or heterogeneity of a dataset, and it is used in CART to determine the best split.\", \"In C4.5 algorithm, missing data can be handled using techniques such as imputation, listwise deletion, or pairwise deletion.\", \"C4.5 and CART are both algorithms for building decision trees, but they differ in their handling of continuous attributes and missing values.\", \"Yes, a decision tree can be used for regression tasks by predicting the target variable instead of class labels.\", \"The performance of a decision tree can be evaluated using metrics such as accuracy, precision, recall, F1-score, mean squared error, or R-squared.\", \"Accuracy is the proportion of correct predictions made by a machine learning model.\", \"Precision is the proportion of true positives among all predicted positive instances.\", \"Recall is the proportion of true positives among all actual positive instances.\", \"F1-score is the harmonic mean of precision and recall, providing a balanced measure of both metrics.\", \"In C4.5 algorithm, continuous attributes can be handled using techniques such as binning or discretization.\", \"Yes, a decision tree can be used for multi-class classification tasks by predicting multiple class labels instead of binary class labels.\", \"The interpretability of a decision tree can be improved by visualizing the tree structure, using feature importance scores, or providing explanations for individual predictions.\", \"Feature importance is a measure of the contribution of each feature to the predictions made by a machine learning model.\", \"Yes, a decision tree can be used for clustering tasks by predicting cluster labels instead of class labels.\", \"Anomaly detection involves identifying instances that are significantly different from the majority of the data, and decision trees can be used for this task.\", \"The robustness of a decision tree can be improved using techniques such as pruning, regularization, or ensemble methods.\", \"Ensemble learning is a technique that combines multiple machine learning models to improve performance and robustness.\", \"Yes, we can combine multiple decision trees to improve performance by voting, bagging, or boosting.\", \"The performance of a decision tree on large-scale data can be improved using distributed computing frameworks such as Hadoop or Spark.\" ] }"
      ],
      "metadata": {
        "id": "MuEOciCbbmsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open(\"qa_db.json\", \"w\") as outfile:\n",
        "#     json.dump(qa_dict, outfile)"
      ],
      "metadata": {
        "id": "_oNQEd1rVFrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dumping Data into JSON:"
      ],
      "metadata": {
        "id": "oC8oNSdHZd6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/qa_db.json'\n",
        "\n",
        "# Read the existing JSON file\n",
        "with open(file_path, 'r') as file:\n",
        "    existing_data = json.load(file)\n",
        "\n",
        "# If the file contains a list of dictionaries, append the new data\n",
        "# Otherwise, if it's just a single dictionary, update its keys\n",
        "if isinstance(existing_data, list):\n",
        "    existing_data.append(qa_dict)\n",
        "else:\n",
        "    # Assuming the existing JSON is a dictionary with 'question' and 'answer' keys\n",
        "    existing_data['question'].extend(qa_dict['question'])\n",
        "    existing_data['answer'].extend(qa_dict['answer'])\n",
        "\n",
        "# Write the updated content back to the JSON file\n",
        "with open(file_path, 'w') as file:\n",
        "    json.dump(existing_data, file, indent=4)\n",
        "\n",
        "print(\"Data has been added to the JSON file successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JghYh92sVSM3",
        "outputId": "4281f7ac-33e7-4b2d-de44-8bad5a4eb210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has been added to the JSON file successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fdjD8zeQcOlV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}